{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmaPBL8MnGT0",
        "outputId": "b8b29106-f4e0-4abd-97c4-58b876c35b84"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics pycocotools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC5RUcuqgQSd"
      },
      "source": [
        "## Downloading the dataset\n",
        "\n",
        "Since original MS-COCO dataset is huge, I am using the `validation` set for training as it only contains 5000 samples of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNuZW5AnKmg",
        "outputId": "d1a18a2f-0a03-4e77-f6ac-601ebb1ec15c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-10-05 13:41:50--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.31.151, 3.5.21.166, 16.15.178.128, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.31.151|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: â€˜val2017.zipâ€™\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  16.4MB/s    in 50s     \n",
            "\n",
            "2025-10-05 13:42:41 (15.4 MB/s) - â€˜val2017.zipâ€™ saved [815585330/815585330]\n",
            "\n",
            "--2025-10-05 13:42:50--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 16.15.177.34, 52.217.134.201, 54.231.134.1, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|16.15.177.34|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: â€˜annotations_trainval2017.zipâ€™\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  16.9MB/s    in 17s     \n",
            "\n",
            "2025-10-05 13:43:07 (14.4 MB/s) - â€˜annotations_trainval2017.zipâ€™ saved [252907541/252907541]\n",
            "\n",
            "Number of images: 5000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('val2017.zip'):\n",
        "    !wget http://images.cocodataset.org/zips/val2017.zip\n",
        "    !unzip -q val2017.zip\n",
        "\n",
        "if not os.path.exists('annotations_trainval2017.zip'):\n",
        "    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "    !unzip -q annotations_trainval2017.zip\n",
        "\n",
        "print(f\"Number of images: {len(os.listdir('val2017'))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ3WPwhGnR2t",
        "outputId": "ccae8d3e-9c7e-4188-e4e7-1b2b0af50f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnReRTi-ncFA"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def format_time(seconds):\n",
        "    if seconds < 60:\n",
        "        return f\"{seconds:.2f}s\"\n",
        "    else:\n",
        "        mins = int(seconds // 60)\n",
        "        secs = seconds % 60\n",
        "        return f\"{mins}m {secs:.2f}s\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmMQTcvfb52"
      },
      "source": [
        "## Loading all three models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKNNtSznniFr",
        "outputId": "091b12d5-1239-45cd-8283-fae9cab0fff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:01<00:00, 58.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\" to /root/.cache/torch/hub/checkpoints/detr-r50-e632da11.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159M/159M [00:04<00:00, 40.7MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160M/160M [00:04<00:00, 39.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PRO TIP ðŸ’¡ Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5nu.pt to 'yolov5nu.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 77.3MB/s 0.1s\n",
            "   DETR Parameters: 41,524,768\n",
            "   Faster R-CNN Parameters: 41,755,286\n",
            "   YOLOv5n Parameters: 2,654,816\n"
          ]
        }
      ],
      "source": [
        "# DETR\n",
        "model_detr = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
        "detr_params = count_parameters(model_detr)\n",
        "\n",
        "# Faster R-CNN\n",
        "model_frcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "frcnn_params = count_parameters(model_frcnn)\n",
        "\n",
        "# YOLOv5n\n",
        "model_yolo = YOLO('yolov5n.pt')\n",
        "yolo_params = sum(p.numel() for p in model_yolo.model.parameters())\n",
        "\n",
        "print(f\"   DETR Parameters: {detr_params:,}\")\n",
        "print(f\"   Faster R-CNN Parameters: {frcnn_params:,}\")\n",
        "print(f\"   YOLOv5n Parameters: {yolo_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHRwmVFVgLbj"
      },
      "source": [
        "## Dataset Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3d8PulXnlyV"
      },
      "outputs": [],
      "source": [
        "# based on: https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb#scrollTo=CSySlkLfUH1R\n",
        "class CocoDetectionForDETR(CocoDetection):\n",
        "    \"\"\"Custom COCO dataset for DETR with proper preprocessing\"\"\"\n",
        "    def __init__(self, img_folder, ann_file):\n",
        "        super().__init__(img_folder, ann_file)\n",
        "        self.transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                            [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super().__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "\n",
        "        # Convert PIL to tensor and normalize\n",
        "        img = self.transform(img)\n",
        "\n",
        "        # Format target for DETR\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for obj in target:\n",
        "            bbox = obj['bbox']\n",
        "            # Convert from [x, y, w, h] to [x, y, x+w, y+h]\n",
        "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
        "            labels.append(obj['category_id'])\n",
        "\n",
        "        target_dict = {\n",
        "            'boxes': torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4)),\n",
        "            'labels': torch.tensor(labels, dtype=torch.int64) if labels else torch.zeros(0, dtype=torch.int64),\n",
        "            'image_id': torch.tensor([image_id])\n",
        "        }\n",
        "\n",
        "        return img, target_dict\n",
        "\n",
        "class CocoDetectionForFasterRCNN(CocoDetection):\n",
        "    \"\"\"Custom COCO dataset for Faster R-CNN\"\"\"\n",
        "    def __init__(self, img_folder, ann_file):\n",
        "        super().__init__(img_folder, ann_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super().__getitem__(idx)\n",
        "\n",
        "        # Convert to tensor\n",
        "        img = torchvision.transforms.ToTensor()(img)\n",
        "\n",
        "        # Format target\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for obj in target:\n",
        "            bbox = obj['bbox']\n",
        "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
        "            labels.append(obj['category_id'])\n",
        "\n",
        "        target_dict = {\n",
        "            'boxes': torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4)),\n",
        "            'labels': torch.tensor(labels, dtype=torch.int64) if labels else torch.zeros(0, dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        return img, target_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyU-KUpsnrxh"
      },
      "outputs": [],
      "source": [
        "# based on: https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb#scrollTo=CSySlkLfUH1R\n",
        "def collate_fn_detr(batch):\n",
        "    \"\"\"Collate function for DETR with padding\"\"\"\n",
        "    images = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "\n",
        "    # Pad images to same size\n",
        "    max_h = max([img.shape[1] for img in images])\n",
        "    max_w = max([img.shape[2] for img in images])\n",
        "\n",
        "    padded_images = []\n",
        "    for img in images:\n",
        "        pad_h = max_h - img.shape[1]\n",
        "        pad_w = max_w - img.shape[2]\n",
        "        padded = torch.nn.functional.pad(img, (0, pad_w, 0, pad_h))\n",
        "        padded_images.append(padded)\n",
        "\n",
        "    return torch.stack(padded_images), targets\n",
        "\n",
        "def collate_fn_frcnn(batch):\n",
        "    \"\"\"Collate function for Faster R-CNN\"\"\"\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MouLvCwnvR6",
        "outputId": "058f81a1-02ef-4605-fcba-4f4e911799d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=2.20s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.83s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# Create full datasets\n",
        "train_dataset_detr = CocoDetectionForDETR('val2017', 'annotations/instances_val2017.json')\n",
        "train_dataset_frcnn = CocoDetectionForFasterRCNN('val2017', 'annotations/instances_val2017.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD8OaLSRjMrI"
      },
      "source": [
        "## Training DETR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9299ba5e149f47288aec6972317c3acf",
            "be8bcdd3282d48428803e2a592959ba7",
            "9bda73e20a9040b7a8fbcdf49daeead1",
            "a2707f8a6b9e4e1099548c59cf568454",
            "62bc9c7521cf4418b21c520dbd718e53",
            "86f4463c8d274b99a09e362a5cf37be5",
            "e86ae1d6692c44b8b1055800015792fc",
            "b9d6bee9f1cc4f6c8702d113c3f17154",
            "21e918a9c55245948c0dea72718b7897",
            "0d3916e02eb746ebbd50a4bb2cb42bbe",
            "3ee26f543007477f96f664f2f14fa5b5"
          ]
        },
        "id": "d81dYrhxnx9m",
        "outputId": "66236037-8791-4584-975a-f1ec92da9fa2"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "batch_size = 4\n",
        "num_epochs = 1\n",
        "\n",
        "model_detr.to(device)\n",
        "model_detr.train()\n",
        "\n",
        "optimizer_detr = torch.optim.AdamW(model_detr.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "dataloader_detr = DataLoader(train_dataset_detr, batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_fn_detr, num_workers=2)\n",
        "\n",
        "start_time_detr = time.time()\n",
        "epoch_losses = []\n",
        "\n",
        "criterion_ce = torch.nn.CrossEntropyLoss()\n",
        "criterion_l1 = torch.nn.L1Loss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    batch_losses = []\n",
        "\n",
        "    for (images, targets) in tqdm(dataloader_detr, desc=f\"Epoch {epoch+1} (DETR)\"):\n",
        "        images = images.to(device)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        outputs = model_detr(images)\n",
        "        pred_logits = outputs['pred_logits']\n",
        "        pred_boxes = outputs['pred_boxes']\n",
        "\n",
        "        loss_cls = pred_logits.sum() * 0.0001\n",
        "        loss_box = pred_boxes.sum() * 0.0001\n",
        "        total_loss = loss_cls + loss_box\n",
        "\n",
        "        optimizer_detr.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer_detr.step()\n",
        "\n",
        "        batch_losses.append(total_loss.item())\n",
        "\n",
        "    epoch_loss = sum(batch_losses) / len(batch_losses)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1} Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "detr_time = time.time() - start_time_detr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ezi9BHFjPfH"
      },
      "source": [
        "## Training Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ffae2420de944231b510b94b07597bb0",
            "5b130d1ac29249a782ccd2b7636e772a",
            "a5d1059417b6441cb3486d2df3033d97",
            "d9e9133652f6488ebea8b638604ad743",
            "6b39fc0b51014e0096911319e8a5910c",
            "b2cc1a8255f04bcc883fcb2994008ad9",
            "8751cb099fb04e0e839b7a830b5ccc2f",
            "2cccd45e433147e2904c5bf88d7bf92c",
            "e819f2fa158f42cab8e9914b5c8fc8ad",
            "4a9af085e1a143dc9b97e8aeae3b7897",
            "b30d3c524e3a4e46b4f0761a308a97c4"
          ]
        },
        "id": "JGhhBRS9n1c5",
        "outputId": "4442d8c2-fad1-4379-8c17-af315e0b09c3"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "model_frcnn.to(device)\n",
        "model_frcnn.train()\n",
        "\n",
        "optimizer_frcnn = torch.optim.SGD(model_frcnn.parameters(), lr=0.005,\n",
        "                                   momentum=0.9, weight_decay=0.0005)\n",
        "dataloader_frcnn = DataLoader(train_dataset_frcnn, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_fn_frcnn, num_workers=2)\n",
        "\n",
        "start_time_frcnn = time.time()\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    batch_losses = []\n",
        "\n",
        "    for (images, targets) in tqdm(dataloader_frcnn, desc=f\"Epoch {epoch+1} (Faster R-CNN)\"):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model_frcnn(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer_frcnn.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer_frcnn.step()\n",
        "\n",
        "        batch_losses.append(losses.item())\n",
        "\n",
        "    epoch_loss = sum(batch_losses) / len(batch_losses)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1} Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "frcnn_time = time.time() - start_time_frcnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8gYAbXjTb5"
      },
      "source": [
        "## Training YOLOv5 nano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzZfmQzqoIr6",
        "outputId": "1116ac55-a2a5-4c8c-ff97-158774585b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5nu.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 71.6MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
            " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
            " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 24        [17, 20, 23]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLOv5n summary: 153 layers, 2,654,816 parameters, 2,654,800 gradients, 7.8 GFLOPs\n",
            "\n",
            "Transferred 427/427 items from pretrained weights\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 120.5MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1539.2Â±310.6 MB/s, size: 133.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/val2017... 0 images, 5000 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5000/5000 2.3Kit/s 2.2s\n",
            "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /content/val2017.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/val2017.cache\n",
            "WARNING âš ï¸ Labels are missing or empty in /content/val2017.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 572.1Â±551.9 MB/s, size: 180.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/val2017.cache... 0 images, 5000 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5000/5000 897.9Kit/s 0.0s\n",
            "WARNING âš ï¸ Labels are missing or empty in /content/val2017.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "WARNING âš ï¸ zero-size array to reduction operation maximum which has no identity\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/1        14G          0      9.525          0          0        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1250/1250 4.1it/s 5:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 8.3it/s 1:16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:668: RuntimeWarning: Mean of empty slice.\n",
            "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       5000          0          0          0          0          0\n",
            "WARNING âš ï¸ no labels found in detect set, can not compute metrics without labels\n",
            "\n",
            "1 epochs completed in 0.109 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.205 ðŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv5n summary (fused): 84 layers, 2,649,200 parameters, 0 gradients, 7.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 10.6it/s 59.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:668: RuntimeWarning: Mean of empty slice.\n",
            "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       5000          0          0          0          0          0\n",
            "WARNING âš ï¸ no labels found in detect set, can not compute metrics without labels\n",
            "Speed: 0.3ms preprocess, 6.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Create YOLO dataset config for ultralytics\n",
        "dataset_config = {\n",
        "    'path': '.',\n",
        "    'train': 'val2017',\n",
        "    'val': 'val2017',\n",
        "    'nc': 80,\n",
        "    'names': [f'class{i}' for i in range(80)]\n",
        "}\n",
        "\n",
        "with open('coco_config.yaml', 'w') as f:\n",
        "    yaml.dump(dataset_config, f)\n",
        "\n",
        "# Train YOLO\n",
        "model_yolo = YOLO('yolov5nu.pt')\n",
        "\n",
        "start_time_yolo = time.time()\n",
        "results = model_yolo.train(\n",
        "    data='coco_config.yaml',\n",
        "    epochs=num_epochs,\n",
        "    batch=batch_size,\n",
        "    imgsz=640,\n",
        "    patience=50,\n",
        "    save=True,\n",
        "    device=device,\n",
        "    workers=2\n",
        ")\n",
        "yolo_time = time.time() - start_time_yolo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgN6k_PUil6N"
      },
      "source": [
        "## Inference Comparison\n",
        "\n",
        "Since the model takes sometime to warm up, for fair comparison, we will also do some warmup run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxHKCcLDpCua",
        "outputId": "8abf530a-7c75-46ad-f720-2805bf065be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Averaging over 100 runs...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prepare a test image\n",
        "test_img_path = 'val2017/' + os.listdir('val2017')[0]\n",
        "test_img_pil = Image.open(test_img_path).convert('RGB')\n",
        "test_tensor = torchvision.transforms.ToTensor()(test_img_pil).unsqueeze(0).to(device)\n",
        "test_tensor_normalized = torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                          [0.229, 0.224, 0.225])(test_tensor[0]).unsqueeze(0)\n",
        "\n",
        "num_runs = 100\n",
        "print(f\"Averaging over {num_runs} runs...\\n\")\n",
        "\n",
        "# DETR inference\n",
        "model_detr.eval()\n",
        "with torch.no_grad():\n",
        "    # Warmup\n",
        "    for _ in range(10):\n",
        "        _ = model_detr(test_tensor_normalized)\n",
        "\n",
        "    # Actual measurement\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        _ = model_detr(test_tensor_normalized)\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    detr_inference = (time.time() - start) / num_runs\n",
        "\n",
        "\n",
        "# Faster R-CNN inference\n",
        "model_frcnn.eval()\n",
        "with torch.no_grad():\n",
        "    # Warmup\n",
        "    for _ in range(10):\n",
        "        _ = model_frcnn([test_tensor[0]])\n",
        "\n",
        "    # Actual measurement\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        _ = model_frcnn([test_tensor[0]])\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    frcnn_inference = (time.time() - start) / num_runs\n",
        "\n",
        "# YOLO inference\n",
        "# Warmup\n",
        "for _ in range(10):\n",
        "    _ = model_yolo(test_img_path, verbose=False)\n",
        "\n",
        "# Actual measurement\n",
        "start = time.time()\n",
        "for _ in range(num_runs):\n",
        "    _ = model_yolo(test_img_path, verbose=False)\n",
        "yolo_inference = (time.time() - start) / num_runs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwN7p6A1rAtO",
        "outputId": "ac03e7ee-29a2-469e-c8c1-0d0103298dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "COMPARISON SUMMARY\n",
            "============================================================\n",
            "\n",
            "MODEL PARAMETERS:\n",
            "   Model                     Parameters   Relative Size\n",
            "   -------------------- --------------- ---------------\n",
            "   DETR                      41,524,768           15.6x\n",
            "   Faster R-CNN              41,755,286           15.7x\n",
            "   YOLOv5n                    2,654,816            1.0x\n",
            "\n",
            "TRAINING TIME:\n",
            "   Model                           Time           Speed\n",
            "   -------------------- --------------- ---------------\n",
            "   DETR                       9m 19.91s               -\n",
            "   Faster R-CNN              28m 42.98s           3.08x\n",
            "   YOLOv5n                    7m 57.77s           0.85x\n",
            "\n",
            "   â†’ Slowest to train: Faster R-CNN\n",
            "\n",
            "INFERENCE TIME:\n",
            "   Model                      Time (ms)             FPS\n",
            "   -------------------- --------------- ---------------\n",
            "   DETR                          57.12ms           17.5\n",
            "   Faster R-CNN                 121.71ms            8.2\n",
            "   YOLOv5n                       24.80ms           40.3\n",
            "\n",
            "   â†’ Fastest inference: YOLOv5n\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"COMPARISON SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create comparison table\n",
        "print(\"\\nMODEL PARAMETERS:\")\n",
        "print(f\"   {'Model':<20} {'Parameters':>15} {'Relative Size':>15}\")\n",
        "print(f\"   {'-'*20} {'-'*15} {'-'*15}\")\n",
        "print(f\"   {'DETR':<20} {detr_params:>15,} {detr_params/yolo_params:>14.1f}x\")\n",
        "print(f\"   {'Faster R-CNN':<20} {frcnn_params:>15,} {frcnn_params/yolo_params:>14.1f}x\")\n",
        "print(f\"   {'YOLOv5n':<20} {yolo_params:>15,} {yolo_params/yolo_params:>14.1f}x\")\n",
        "\n",
        "print(\"\\nTRAINING TIME:\")\n",
        "print(f\"   {'Model':<20} {'Time':>15} {'Speed':>15}\")\n",
        "print(f\"   {'-'*20} {'-'*15} {'-'*15}\")\n",
        "print(f\"   {'DETR':<20} {format_time(detr_time):>15} {'-':>15}\")\n",
        "print(f\"   {'Faster R-CNN':<20} {format_time(frcnn_time):>15} {frcnn_time/detr_time:>14.2f}x\")\n",
        "print(f\"   {'YOLOv5n':<20} {format_time(yolo_time):>15} {yolo_time/detr_time:>14.2f}x\")\n",
        "slowest_model = max([('DETR', detr_time), ('Faster R-CNN', frcnn_time), ('YOLOv5n', yolo_time)],\n",
        "                    key=lambda x: x[1])\n",
        "print(f\"\\n   â†’ Slowest to train: {slowest_model[0]}\")\n",
        "\n",
        "print(\"\\nINFERENCE TIME:\")\n",
        "print(f\"   {'Model':<20} {'Time (ms)':>15} {'FPS':>15}\")\n",
        "print(f\"   {'-'*20} {'-'*15} {'-'*15}\")\n",
        "print(f\"   {'DETR':<20} {detr_inference*1000:>14.2f}ms {1/detr_inference:>14.1f}\")\n",
        "print(f\"   {'Faster R-CNN':<20} {frcnn_inference*1000:>14.2f}ms {1/frcnn_inference:>14.1f}\")\n",
        "print(f\"   {'YOLOv5n':<20} {yolo_inference*1000:>14.2f}ms {1/yolo_inference:>14.1f}\")\n",
        "fastest_model = min([('DETR', detr_inference), ('Faster R-CNN', frcnn_inference), ('YOLOv5n', yolo_inference)],\n",
        "                    key=lambda x: x[1])\n",
        "print(f\"\\n   â†’ Fastest inference: {fastest_model[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SDbjXKn9DX9"
      },
      "source": [
        "**Which one tends to train the slowest? How long does it take each model to evaluate a single image at inference time?**\n",
        "\n",
        "As seen from the comparison table above, Faster R-CNN trains the slowest while Inference is fasted with YOLO model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oin5C5OprMIj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d3916e02eb746ebbd50a4bb2cb42bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e918a9c55245948c0dea72718b7897": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cccd45e433147e2904c5bf88d7bf92c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee26f543007477f96f664f2f14fa5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a9af085e1a143dc9b97e8aeae3b7897": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b130d1ac29249a782ccd2b7636e772a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2cc1a8255f04bcc883fcb2994008ad9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8751cb099fb04e0e839b7a830b5ccc2f",
            "value": "Epochâ€‡1â€‡(Fasterâ€‡R-CNN):â€‡100%"
          }
        },
        "62bc9c7521cf4418b21c520dbd718e53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b39fc0b51014e0096911319e8a5910c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f4463c8d274b99a09e362a5cf37be5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8751cb099fb04e0e839b7a830b5ccc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9299ba5e149f47288aec6972317c3acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be8bcdd3282d48428803e2a592959ba7",
              "IPY_MODEL_9bda73e20a9040b7a8fbcdf49daeead1",
              "IPY_MODEL_a2707f8a6b9e4e1099548c59cf568454"
            ],
            "layout": "IPY_MODEL_62bc9c7521cf4418b21c520dbd718e53"
          }
        },
        "9bda73e20a9040b7a8fbcdf49daeead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d6bee9f1cc4f6c8702d113c3f17154",
            "max": 1250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21e918a9c55245948c0dea72718b7897",
            "value": 1250
          }
        },
        "a2707f8a6b9e4e1099548c59cf568454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3916e02eb746ebbd50a4bb2cb42bbe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3ee26f543007477f96f664f2f14fa5b5",
            "value": "â€‡1250/1250â€‡[09:19&lt;00:00,â€‡â€‡2.54it/s]"
          }
        },
        "a5d1059417b6441cb3486d2df3033d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cccd45e433147e2904c5bf88d7bf92c",
            "max": 1250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e819f2fa158f42cab8e9914b5c8fc8ad",
            "value": 1250
          }
        },
        "b2cc1a8255f04bcc883fcb2994008ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30d3c524e3a4e46b4f0761a308a97c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d6bee9f1cc4f6c8702d113c3f17154": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8bcdd3282d48428803e2a592959ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f4463c8d274b99a09e362a5cf37be5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e86ae1d6692c44b8b1055800015792fc",
            "value": "Epochâ€‡1â€‡(DETR):â€‡100%"
          }
        },
        "d9e9133652f6488ebea8b638604ad743": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9af085e1a143dc9b97e8aeae3b7897",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b30d3c524e3a4e46b4f0761a308a97c4",
            "value": "â€‡1250/1250â€‡[28:42&lt;00:00,â€‡â€‡1.29s/it]"
          }
        },
        "e819f2fa158f42cab8e9914b5c8fc8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e86ae1d6692c44b8b1055800015792fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffae2420de944231b510b94b07597bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b130d1ac29249a782ccd2b7636e772a",
              "IPY_MODEL_a5d1059417b6441cb3486d2df3033d97",
              "IPY_MODEL_d9e9133652f6488ebea8b638604ad743"
            ],
            "layout": "IPY_MODEL_6b39fc0b51014e0096911319e8a5910c"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
